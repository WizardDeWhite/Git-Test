1. setup_numabalancing(), __setup()
================================================================================
1.1 numabalancing_override = 1
================================================================================

1. numa_policy_init(), called by start_kernel()
================================================================================
1.1 policy_cache = kmem_cache_create("numa_policy")
================================================================================
1.2 sn_cache = kmem_cache_create("shared_policy_node")
================================================================================
1.3 preferred_node_policy[nid] = {}
================================================================================
1.4 do_set_mempolicy(MPOL_INTERLEAVE, 0, &interleave_nodes)
================================================================================
1.4.1 new = mpol_new()
================================================================================
1.4.2 mpol_set_nodemask(new, nodes, scratch)
================================================================================
1.4.3 current->mempolicy = new
================================================================================
1.5 check_numabalancing_enable()
================================================================================
1.5.1 set_numabalancing_state(numabalancing_default);
================================================================================
1.5.1.1 static_branch_enable(&sched_numa_balancing), enable numa balance
================================================================================

2. sched_fork()
================================================================================
2.1 __sched_fork()
================================================================================
2.1.1 init_numa_balancing(clone_flags, struct task_struct p)
================================================================================
2.1.1.1 p->numa_work.next = &p->numa_work
================================================================================
2.1.1.2 init_task_work(&p->numa_work, task_numa_work)
================================================================================

3. task_tick_numa(), called by task_tick_fair if sched_numa_balancing
================================================================================
3.1 work = &curr->numa_work
================================================================================
3.2 task_work_add(curr, work, true), add work to curr->task_works
================================================================================

4. task_numa_work(), do the numa balancing
================================================================================
4.1 start = current->numa_scan_offset
================================================================================
4.2 mmap_read_trylock(mm)
================================================================================
4.3 vma = find_vma(mm, start)
================================================================================
4.4 !vma_migratable(vma) || !vma_policy_mof(vma) || is_vm_hugetlb_page(vma) || 
================================================================================
4.5 nr_pte_updates = change_prot_numa(vma, start, end);
================================================================================
4.5.1 change_protection(vma, addr, end, PAGE_NONE, MM_CP_PROT_NUMA)
================================================================================
4.5.1.1 hugetlb_change_protection(vma, addr, end, newprot)
================================================================================
4.5.1.2 change_protection_range(vma, addr, end, newprot, cp_flags), adjust pte with newprot
================================================================================
4.6 mm->numa_scan_offset = start
================================================================================
4.7 mmap_read_unlock(mm)
================================================================================

5. do_anonymous_page()
================================================================================
5.1 alloc_zeroed_user_highpage_movable() -> __alloc_zeroed_user_highpage()
================================================================================
5.1.1 alloc_pages_vma(), alloc with NUMA policy(understand how policy works)
================================================================================
5.1.1.1 pol = get_vma_policy(vma, addr), pol from vma or task policy
================================================================================
5.1.1.2 alloc_page_interleave(), if pol->mode == MPOL_INTERLEAVE
================================================================================
5.1.1.3 nmask = policy_nodemask()
================================================================================

6. first numa policy
================================================================================

start_kernel()
    arch_call_rest_init()
        rest_init()
	    kernel_thread(kernel_init, )
                numa_default_policy()
                    do_set_mempolicy(MPOL_DEFAULT, 0, NULL)
            numa_default_policy()

7. set_mempolicy() -> kernel_set_mempolicy()
================================================================================
7.1 get_nodes(&nodes, nmask, maxnode)
================================================================================
7.2 do_set_mempolicy(mode, flags, &nodes)
================================================================================
7.2.1 new = mpol_new(mode, flags, nodes)
================================================================================
7.2.2 task_lock(current)
================================================================================
7.2.3 mpol_set_nodemask(new, nodes, scratch)
================================================================================
7.2.4 old = current->mempolicy
================================================================================
7.2.5 current->mempolicy = new
================================================================================
7.2.6 task_unlock(current)
================================================================================
7.2.7 mpol_put(old)
================================================================================

8. mbind(start, len, mode, nmask, maxnode, flags) -> kernel_mbind()
================================================================================
8.1 get_nodes(&nodes, nmask, maxnode)
================================================================================
8.2 do_mbind(start, len, mode, mode_flags, &nodes, flags)
================================================================================
8.2.1 new = mpol_new(mode, mode_flags, nmask)
================================================================================
8.2.2 migrate_prep()
================================================================================
8.2.2.1 lru_add_drain_all()
================================================================================
8.2.3 queue_pages_range(mm, start, end, nmask, flags | MPOL_MF_INVERT, &pagelist)
================================================================================
8.2.4 mbind_range(mm, start, end, new), apply policy to vma
================================================================================
8.2.5 migrage_pages(&pagelist, new_page, NULL, start, )
================================================================================

9. mpol_new(mode, flags, nodes)
================================================================================
9.1 return NULL, if mode == MPOL_DEFAULT
================================================================================
9.2 policy = kmem_cache_alloc(policy_cache, GFP_KERNEL)
================================================================================
9.3 atomic_set(&policy->refcnt, 1)
================================================================================
9.4 policy->mode = mode
================================================================================
9.5 policy->flags = flags
================================================================================

10. mpol_set_nodemask(new, nodes, scratch)
================================================================================
10.1 nodes_and(scratch->mask1, cpuset_current_mems_allowed, node_states[N_MEMORY])
================================================================================
10.2 mpol_relative_nodemask(&scratch->mask2, nodes, &scratch->mask1)
================================================================================
10.2.1 nodes_fold(tmp, nodes, nodes_weight(&scratch->mask1))
================================================================================
10.2.2 nodes_onto(&scratch->mask2, tmp, &scratch->mask1)
================================================================================
10.3 nodes_and(&scratch->mask2, nodes, &scratch->mask1)
================================================================================
10.4 mpol_ops[pol->mode].create(pol, &scratch->mask2 : NULL)
================================================================================

0. data struct
================================================================================

0.0 global variables
================================================================================
NUMA policy allows the user to give hints in which node(s) memory should
be allocated

enum {
	MPOL_DEFAULT,
	MPOL_PREFERRED,
	MPOL_BIND,
	MPOL_INTERLEAVE,
	MPOL_LOCAL,
	MPOL_MAX,	/* always last member of enum */
};

default_policy
     (struct mempolic)
preferred_node_policy[MAX_NUMNODES]
     (struct mempolic)

0.1 mempolicy
================================================================================

    mempolicy
    +------------------------------+
    |refcnt                        |
    |    (atomic_t)                |
    |mode                          |
    |flags                         |
    |    (unsigned short)          |
    |v                             |
    |   +--------------------------+
    |   |preferred_node            |   MPOL_PREFERRED
    |   |   (short)                |
    |   |nodes                     |   MPOL_INTERLEAVE/MPOL_BIND
    |   |   (nodemask_t)           |
    |   +--------------------------+
    |w                             |
    |   +--------------------------+
    |   |cpuset_mems_allowed       |
    |   |user_nodemask             |
    |   |   (nodemask_t)           |
    +---+--------------------------+

0.2 mempolicy_operations
================================================================================

    mempolicy_operations
    +------------------------------+
    |create                        |
    |                              |
    |rebind                        |
    |                              |
    +------------------------------+

0.2.1 mpol_ops(struct mempolicy_operations)
================================================================================

    mpol_ops[MPOL_MAX]
                  +------------------------------+
 MPOL_DEFAULT     |create                        |  = NULL
                  |                              |
                  |rebind                        |  = mpol_rebind_default
                  |                              |
                  +------------------------------+
                  +------------------------------+
 MPOL_INTERLEAVE  |create                        |  = mpol_new_interleave
                  |                              |
                  |rebind                        |  = mpol_rebind_nodemask
                  |                              |
                  +------------------------------+
                  +------------------------------+
 MPOL_PREFERRED   |create                        |  = mpol_new_preferred
                  |                              |
                  |rebind                        |  = mpol_rebind_preferred
                  |                              |
                  +------------------------------+
                  +------------------------------+
 MPOL_BIND        |create                        |  = mpol_new_bind
                  |                              |
                  |rebind                        |  = mpol_rebind_nodemask
                  |                              |
                  +------------------------------+

0.3 mempolicy and task / vma
================================================================================

                 task_struct
                 +----------------------+
                 |mempolicy             |  or fallback to default_policy
                 |   (struct mempolicy*)|
                 |mm                    |
                 |   (struct mm_struct*)|
                 +----------------------+
                    /               \
                 /                    \
              /                         \
           /                              \
      vma                              vma
      +------------------------+       +------------------------+
      |vm_ops                  |       |vm_ops                  |
      |    get_policy          |       |    get_policy          |
      |                        |       |                        |
      |vm_policy               |       |vm_policy               |
      |    (struct mempolicy*) |       |    (struct mempolicy*) |
      +------------------------+       +------------------------+
