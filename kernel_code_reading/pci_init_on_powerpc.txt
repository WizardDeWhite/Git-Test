0. pci initialization related code on powernv
===============================================================================
pnv_pci_init();    called in start_kernel()->setup_arch()
pcibios_init();    called in start_kernel()->res_init()->kernel_init()->
                             do_basic_setup()->do_initcalls()

1. pnv_pci_init(), initialize hub and phb
===============================================================================
start_kernel()
	setup_arch(); arch/powerpc/kernel/setup_64.c
		ppc_md.setup_arch(); ppc_md is setup in probe_machine, 
		                   ; see "machine type initialization"
		pnv_setup_arch()
			pnv_pci_init();

pnv_pci_init()
	pci_add_flags(PCI_CAN_SKIP_ISA_ALIGN)
	for_each_compatible_node(np, NULL, "ibm,ioda-hub") {
		pnv_pci_init_ioda_hub(np); go throught the device tree and init ioda-hub
		found_ioda = 1;
	}
	/* Look for p5ioc2 IO-Hubs */
	if (!found_ioda)
		for_each_compatible_node(np, NULL, "ibm,p5ioc2")
			pnv_pci_init_p5ioc2_hub(np);
	
	/* Setup the linkage between OF nodes and PHBs */
	pci_devs_phb_init()

	/* Configure IOMMU DMA hooks */
	ppc_md.pci_dma_dev_setup = pnv_pci_dma_dev_setup;
	ppc_md.tce_build = pnv_tce_build;
	ppc_md.tce_free = pnv_tce_free;
	ppc_md.pci_probe_mode = pnv_pci_probe_mode;
	set_pci_dma_ops(&dma_iommu_ops);

	/* Configure MSIs */
	ppc_md.msi_check_device = pnv_msi_check_device;
	ppc_md.setup_msi_irqs = pnv_setup_msi_irqs;
	ppc_md.teardown_msi_irqs = pnv_teardown_msi_irqs;

1.1 pnv_pci_init_ioda_hub
===============================================================================
pnv_pci_init_ioda_hub(); go through each phb under ioda-hub
	/* Count child PHBs */
	for_each_child_of_node(np, phbn) {
		/* Look for IODA1 PHBs */
		if (of_device_is_compatible(phbn, "ibm,ioda-phb"))
			pnv_pci_init_ioda1_phb(phbn);
	}

  +---------------------------------------------------------------+
  |                                                               |
  |                                                               |
  |                             Hub                               |
  |                                                               |
  |                                                               |
  |  +------+  +------+  +------+  +------+  +------+  +------+   |                                      |
  |  | Phb  |  | Phb  |  | Phb  |  | Phb  |  | Phb  |  | Phb  |   |                                      |
  |  |      |  |      |  |      |  |      |  |      |  |      |   |                                      |
  |  +------+  +------+  +------+  +------+  +------+  +------+   |                                      |
  |                                                               |
  +---------------------------------------------------------------+
   
          Figure 1.1 Relationship between Hub and Phb


1.1.1 pnv_pci_init_ioda1_phb()
===============================================================================
; create a pci_controller for phb
; go through the device tree and retrieve the io/mem resource vale
; stroe them in the pci_controller
; after that, divide those resource equally to PEs.
pnv_pci_init_ioda1_phb();
	prop64 = of_get_property(np, "ibm,opal-phbid", NULL)
	phb_id = be64_to_cpup(prop64);
	phb = alloc_bootmem(sizeof(struct pnv_phb));
	if (phb) {
		memset(phb, 0, sizeof(struct pnv_phb));
		phb->hose = hose = pcibios_alloc_controller(np); will add to hose_list
	}

	spin_lock_init(&phb->lock);
	/* XXX Use device-tree */
	hose->first_busno = 0;
	hose->last_busno = 0xff;
	hose->private_data = phb;
	phb->opal_id = phb_id;
	phb->type = PNV_PHB_IODA1;

	/* Detect specific models for error handling */
	if (of_device_is_compatible(np, "ibm,p7ioc-pciex"))
		phb->model = PNV_PHB_MODEL_P7IOC;
	else
		phb->model = PNV_PHB_MODEL_UNKNOWN;

	/* We parse "ranges" now since we need to deduce the register base
	 * from the IO base
	 */
	pci_process_bridge_OF_ranges(phb->hose, np, primary);
	phb->regs = of_iomap(np, 0);

	; we have 128 PEs
	; calculate the mem32_segsize, io_segsize, 
	phb->ioda.total_pe = 128;
	; calculate the m32_segsize
	phb->ioda.m32_size = resource_size(&hose->mem_resources[0]);
	phb->ioda.m32_size += 0x10000;
	phb->ioda.m32_segsize = phb->ioda.m32_size / phb->ioda.total_pe;
	phb->ioda.m32_pci_base = hose->mem_resources[0].start -
	                         hose->pci_mem_offset; convert back to the pci_addr

	; calculate the io_segsize
	phb->ioda.io_size = hose->pci_io_size;
	phb->ioda.io_segsize = phb->ioda.io_size / phb->ioda.total_pe;
	phb->ioda.io_pci_base = 0;

	; allocate aux data & array
	; for pe_alloc, m32_segmap, io_segmap, pe_array
	INIT_LIST_HEAD(&phb->ioda.pe_list)

	; Calculate how many 32-bit TCE segment we have
	phb->ioda.tce32_count = phb->ioda.m32_pci_base >> 28; 2^26=256M

	/* Clear unusable m64 */
	; just have one m64 resource?
	hose->mem_resources[1].flags = 0;
	hose->mem_resources[1].start = 0;
	hose->mem_resources[1].end = 0;
	hose->mem_resources[2].flags = 0;
	hose->mem_resources[2].start = 0;
	hose->mem_resources[2].end = 0;

	phb->hose->ops = &pnv_pci_ops;

	/* Setup RID -> PE mapping function */
	phb->bdfn_to_pe = pnv_ioda_bdfn_to_pe; setup RID -> PE mapping function

	; setup TCEs
	phb->dma_dev_setup = pnv_pci_ioda_dma_dev_setup; 
	; setup msi support
	pnv_pci_init_ioda_msis(phb); setup msi

	ppc_md.pcibios_fixup = pnv_pci_ioda_fixup;
	ppc_md.pcibios_enable_device_hook = pnv_pci_enable_device_hook;
	ppc_md.pcibios_window_alignment = pnv_pci_window_alignment;
	pci_add_flags(PCI_REASSIGN_ALL_RSRC);

	/* Reset IODA tables to a clean state */
	rc = opal_pci_reset(phb_id, OPAL_PCI_IODA_TABLE_RESET, OPAL_ASSERT_RESET);
	opal_pci_set_pe(phb_id, 0, 0, 7, 1, 1 , OPAL_MAP_PE);


           hose_list(struct list_head)
           +---------------+
           | next          |---+
           +---------------+   |
                        +------+
                        |
		        |   hose(struct pci_controller)
                        +-->+---------------------------------+<----+
                            |first_busno(int)                 |     |
                            +---------------------------------+     |
                            |last_busno(int)                  |     |
                            +---------------------------------+     |
                            |io_resource                      |     |
                            +---------------------------------+     |
                            |mem_resources[](struct resource) |     |
                            +---------------------------------+     |
                            |ops(struct pci_ops*)             |     |
                            +---------------------------------+     |
                            |private_data(void*)              |     |
                            +----+----------------------------+     |
                                 |                                  |
                        +--------+                                  |
                        |                                           |
                        |                                           |
                        |                                           |
                        |                                           |
                        |   phb(struct pnv_phb)                     |
                        +->+---------------------------------+      |
                           |hose(struct pci_controller*)     |----+-+
                           +---------------------------------+
                           |ioda                             |
                           |    total_pe                     |
                           |    io_size                      |
                           |    io_segsize                   |
                           |    m32_size                     |
                           |    m32_segsize                  | 
                           +---------------------------------+ 
          
              Figure 1.2 Relationship between phb and pci_controller



1.1.1.1 pci_process_bridge_OF_ranges(), set hose->mem_resources, hose->io_resource from FDT
===============================================================================
this function read in the device tree property and 
allocate resource in hose->mem_resources or hose->io_resource

read the information from device tree and accroding to the *ranges* field of phb
to assign the resources. For example:
0x2000000 0x0 0x80000000 0x3da0 0x0       0x0 0x7fff0000
pci address              cpu address      size

This page shows the detailed information about it.
http://devicetree.org/Device_Tree_Usage

pci_process_bridge_OF_ranges(struct pci_controller *hose, struct device_node *dev, 
		             int primary)
	pci_space = ranges[0];
	pci_addr = of_read_number(ranges + 1, 2);
	cpu_addr = of_translate_address(dev, ranges + 3);
	size = of_read_number(ranges + pna + 3, 2);

	; mem resource
	hose->pci_mem_offset = cpu_addr - pci_addr;
	res = &hose->mem_resources[];

	; io resource
	hose->pci_io_size = pci_addr + size;
	hose->io_base_phys = cpu_addr - pci_addr; here pci_addr for I/O is 0
	res = &hose->io_resource;

	res->start = cpu_addr;
	res->end = res->start + size - 1;
	res->parent = NULL;
	res->sibling = NULL;
	res->child = NULL;

1.2 pci_devs_phb_init
===============================================================================
 * This routine walks over all phb's (pci-host bridges) on the
 * system, and sets up assorted pci-related structures 
 * (including pci info in the device node structs) for each
 * pci device found underneath.  This routine runs once,
 * early in the boot sequence.

pci_devs_phb_init(void)
	struct pci_controller *phb, *tmp;

	/* This must be done first so the device nodes have valid pci info! */
	list_for_each_entry_safe(phb, tmp, &hose_list, list_node)
		pci_devs_phb_init_dynamic(phb);


1.2.1 pci_devs_phb_init_dynamic
===============================================================================
pci_devs_phb_init_dynamic(struct pci_controller *phb)
	struct device_node *dn = phb->dn;
	struct pci_dn *pdn;

	/* PHB nodes themselves must not match */
	update_dn_pci_info(dn, phb);
	pdn = dn->data;
	if (pdn) {
		pdn->devfn = pdn->busno = -1;
		pdn->phb = phb;
	}

	/* Update dn->phb ptrs for new phb and children devices */
	traverse_pci_devices(dn, update_dn_pci_info, phb);

1.2.1.1 update_dn_pci_info, allocate dn for phb and set busno/devfn from FDT
===============================================================================
update_dn_pci_info(struct device_node *dn, void *data)
	struct pci_controller *phb = data;
	const int *type =
		of_get_property(dn, "ibm,pci-config-space-type", NULL);
	const u32 *regs;
	struct pci_dn *pdn;

	pdn = zalloc_maybe_bootmem(sizeof(*pdn), GFP_KERNEL);
	if (pdn == NULL)
		return NULL;
	dn->data = pdn;
	pdn->node = dn;
	pdn->phb = phb;
#ifdef CONFIG_PPC_POWERNV
	pdn->pe_number = IODA_INVALID_PE;
#endif
	regs = of_get_property(dn, "reg", NULL);
	if (regs) {
		/* First register entry is addr (00BBSS00)  */
		pdn->busno = (regs[0] >> 16) & 0xff;
		pdn->devfn = (regs[0] >> 8) & 0xff;
	}

	pdn->pci_ext_config_space = (type && *type == 1);
	return NULL;

1.2.1.2 traverse_pci_devices, traverse through the pci tree and call update_dn_pci_info for each device
===============================================================================
traverse_pci_devices(struct device_node *start, traverse_func pre,
		void *data)
	struct device_node *dn, *nextdn;
	void *ret;

	/* We started with a phb, iterate all childs */
	for (dn = start->child; dn; dn = nextdn) {
		const u32 *classp;
		u32 class;

		nextdn = NULL;
		classp = of_get_property(dn, "class-code", NULL);
		class = classp ? *classp : 0;

		if (pre && ((ret = pre(dn, data)) != NULL))
			return ret;

		/* If we are a PCI bridge, go down */
		if (dn->child && ((class >> 8) == PCI_CLASS_BRIDGE_PCI ||
				  (class >> 8) == PCI_CLASS_BRIDGE_CARDBUS))
			/* Depth first...do children */
			nextdn = dn->child;
		else if (dn->sibling)
			/* ok, try next sibling instead. */
			nextdn = dn->sibling;
		if (!nextdn) {
			/* Walk up to next valid sibling. */
			do {
				dn = dn->parent;
				if (dn == start)
					return NULL;
			} while (dn->sibling == NULL);
			nextdn = dn->sibling;
		}
	}
	return NULL;

2. pcibios_init()
===============================================================================
pcibios_init()
	ppc_md.phys_mem_access_prot = pci_phys_mem_access_prot;

	/* On ppc64, we always enable PCI domains and we keep domain 0
	 * backward compatible in /proc for video cards
	 */
	pci_add_flags(PCI_ENABLE_PROC_DOMAINS | PCI_COMPAT_DOMAIN_0);

	/* Scan all of the recorded PCI controllers.  */
	list_for_each_entry_safe(hose, tmp, &hose_list, list_node) {
		; create the whole pci tree
		pcibios_scan_phb(hose);
		; register the pci_dev/pci_bus->dev to system
		pci_bus_add_devices(hose->bus);
	}

	/* Call common code to handle resource allocation */
	pcibios_resource_survey();

2.1. pcibios_scan_phb()
===============================================================================
pcibios_scan_phb()
	; Get some IO space for the new PHB 
	pcibios_setup_phb_io_space(hose);

	; Wire up PHB bus resources 
	; add the io/mem resource to *resources* list
	pcibios_setup_phb_resources(hose, &resources);

	; Create an empty bus for the toplevel 
	; *resources* contains the io/mem resource info from device tree
	; after this step this info is passed to the root bus
	bus = pci_create_root_bus(hose->parent, hose->first_busno,
				  hose->ops, hose, &resources);
	hose->bus = bus;

	/* Get probe mode and perform scan */
	mode = PCI_PROBE_NORMAL;
	if (node && ppc_md.pci_probe_mode)
		mode = ppc_md.pci_probe_mode(bus);pnv_pci_probe_mode

	if (mode == PCI_PROBE_DEVTREE) {
		bus->subordinate = hose->last_busno;
		of_scan_bus(node, bus);
	}

	if (mode == PCI_PROBE_NORMAL); create the bus tree
		hose->last_busno = bus->subordinate = pci_scan_child_bus(bus);

	if (ppc_md.pcibios_fixup_phb)
		ppc_md.pcibios_fixup_phb(hose); it is null now

	/* Configure PCI Express settings */
	if (bus && !pci_has_flag(PCI_PROBE_ONLY)) {
		struct pci_bus *child;
		list_for_each_entry(child, &bus->children, node) {
			; child->self points to the bridge
			struct pci_dev *self = child->self;
			if (!self)
				continue;
			pcie_bus_configure_settings(child, self->pcie_mpss);
		}
	}

2.1.1 pcibios_setup_phb_io_space(), map the physical address to virtual address
===============================================================================
pcibios_setup_phb_io_space(struct pci_controller *hose) 
	pcibios_map_phb_io_space(hose)

picbios_map_phb_io_space(struct pci_controller *hose)
	struct vm_struct *area;

	phys_page = _ALIGN_DOWN(hose->io_base_phys, PAGE_SIZE);
	size_page = _ALIGN_UP(hose->pci_io_size, PAGE_SIZE);

	area = __get_vm_area(size_page, 0, PHB_IO_BASE, PHB_IO_END);

	hose->io_base_alloc = area->addr; virtual address allocated
	hose->io_base_virt = (void __iomem *)
              (area->addr + hose->io_base_phys - phys_page);
	      ; virtual address which map to hose->io_base_phys

	; map it
	if (__ioremap_at(phys_page, area->addr, size_page,
			 _PAGE_NO_CACHE | _PAGE_GUARDED) == NULL)

	; Fixup hose IO resource
	io_virt_offset = pcibios_io_space_offset(hose);
	hose->io_resource.start += io_virt_offset;
	hose->io_resource.end += io_virt_offset;

2.1.2 pcibios_setup_phb_resources(), add io/mem resource, which is read from FDT , to list
===============================================================================
pcibios_setup_phb_resources(struct pci_controller *hose, struct list_head *resources)
	res = &hose->io_resource;

	; add io resource to *resources* list
	pci_add_resource_offset(resources, res, pcibios_io_space_offset(hose));


	; add mem resource to *resources* list
	for (i = 0; i < 3; ++i) {
		res = &hose->mem_resources[i];
		if (!res->flags) {
			if (i > 0)
				continue;
		}

		pci_add_resource_offset(resources, res, hose->pci_mem_offset);
	}

2.1.3 pnv_pci_probe_mode()
===============================================================================
pnv_pci_probe_mode()
	return PCI_PROBE_NORMAL;

2.1.4 pci_scan_child_bus(), enumerate the pci tree
===============================================================================
this is a core function which is used to enumerate the pci tree

2.1.5 pnv_pci_ioda_fixup_phb()
===============================================================================
pnv_pci_ioda_fixup_phb()
	; associate PEs per function
	pnv_ioda_setup_PEs(hose->bus);

	; calculate all resources
	pnv_ioda_calc_bus(hose->bus, IORESOURCE_IO, &size, &align);
	pnv_ioda_calc_bus(hose->bus, IORESOURCE_MEM, &size, &align);

	; apply them to HW
	pnv_ioda_update_resources(hose->bus);

	; setup DMA
	pnv_ioda_setup_dma(hose->private_data);

	; Configure PCI Express settings 
	list_for_each_entry(child, &hose->bus->children, node) {
		struct pci_dev *self = child->self;
		if (!self)
			continue;
		pcie_bus_configure_settings(child, self->pcie_mpss);
	}

2.1.5.1 pnv_ioda_setup_PEs(), associate PEs per function
===============================================================================
; originally passed the root bus
; two kinds of PEs
pnv_ioda_setup_PEs(struct pci_bus *bus)
	struct pci_dev *dev;
	struct pnv_ioda_pe *pe;

	; traverse the devices first
	list_for_each_entry(dev, &bus->devices, bus_list) {
		pe = pnv_ioda_setup_dev_PE(dev);
		if (pe == NULL)
			continue;
		/* Leaving the PCIe domain ... single PE# */
		if (dev->pcie_type == PCI_EXP_TYPE_PCI_BRIDGE)
			pnv_ioda_setup_bus_PE(dev, pe);
		else if (dev->subordinate)
			pnv_ioda_setup_PEs(dev->subordinate);
	}

2.1.5.1.1 pnv_ioda_setup_dev_PE(), 
===============================================================================
pnv_ioda_setup_dev_PE(struct pci_dev *dev)
	struct pci_controller *hose = pci_bus_to_host(dev->bus);
	struct pnv_phb *phb = hose->private_data;
	struct pci_dn *pdn = pnv_ioda_get_pdn(dev);
	struct pnv_ioda_pe *pe;
	int pe_num;

	/* PE#0 has been pre-set */
	; find a available pe number
	if (dev->bus->number == 0)
		pe_num = 0;
	else
		pe_num = pnv_ioda_alloc_pe(phb);

	if (pe_num == IODA_INVALID_PE) {
		pr_warning("%s: Not enough PE# available, disabling device\n",
			   pci_name(dev));
		return NULL;
	}

	pe = &phb->ioda.pe_array[pe_num];
	pci_dev_get(dev);
	; associate the dev with this PE
	pdn->pcidev = dev;
	pdn->pe_number = pe_num;
	pe->pdev = dev;
	pe->pbus = NULL;
	pe->tce32_seg = -1;
	pe->mve_number = -1;
	pe->rid = dev->bus->number << 8 | pdn->devfn;

	pe_info(pe, "Associated device to PE\n");

	if (pnv_ioda_configure_pe(phb, pe)) {
		/* XXX What do we do here ? */
		if (pe_num)
			pnv_ioda_free_pe(phb, pe_num);
		pdn->pe_number = IODA_INVALID_PE;
		pe->pdev = NULL;
		pci_dev_put(dev);
		return NULL;
	}

	/* Assign a DMA weight to the device */
	pe->dma_weight = pnv_ioda_dma_weight(dev);
	if (pe->dma_weight != 0) {
		phb->ioda.dma_weight += pe->dma_weight;
		phb->ioda.dma_pe_count++;
	}

	/* Link the PE */
	; add to the link list
	pnv_ioda_link_pe_by_weight(phb, pe);

	return pe;

2.1.5.1.2 pnv_ioda_setup_bus_PE(), 
===============================================================================
pnv_ioda_setup_bus_PE(struct pci_dev *dev, struct pnv_ioda_pe *ppe)
	struct pci_controller *hose = pci_bus_to_host(dev->bus);
	struct pnv_phb *phb = hose->private_data;
	struct pci_bus *bus = dev->subordinate;
	struct pnv_ioda_pe *pe;
	int pe_num;

	pe_num = pnv_ioda_alloc_pe(phb);
	if (pe_num == IODA_INVALID_PE) {
		pr_warning("%s: Not enough PE# available, disabling bus\n",
			   pci_name(dev));
		return;
	}

	pe = &phb->ioda.pe_array[pe_num];
	; means the parent?
	ppe->bus_pe = pe;
	; associate with the bus
	pe->pbus = bus;
	pe->pdev = NULL;
	pe->tce32_seg = -1;
	pe->mve_number = -1;
	pe->rid = bus->secondary << 8;
	pe->dma_weight = 0;

	if (pnv_ioda_configure_pe(phb, pe)) {
		/* XXX What do we do here ? */
		if (pe_num)
			pnv_ioda_free_pe(phb, pe_num);
		pe->pbus = NULL;
		return;
	}

	/* Associate it with all child devices */
	pnv_ioda_setup_same_PE(bus, pe);

	/* Account for one DMA PE if at least one DMA capable device exist
	 * below the bridge
	 */
	if (pe->dma_weight != 0) {
		phb->ioda.dma_weight += pe->dma_weight;
		phb->ioda.dma_pe_count++;
	}

	/* Link the PE */
	pnv_ioda_link_pe_by_weight(phb, pe);

2.1.5.2 pnv_ioda_calc_bus(), calculate the total resource size and largest alignment
===============================================================================
; and arrange the resources in each bus and dev
pnv_ioda_calc_bus(struct pci_bus *bus, unsigned int flags, 
		  resource_size_t *size,
		  resource_size_t *align)
	struct pci_controller *hose = pci_bus_to_host(bus);
	struct pnv_phb *phb = hose->private_data;
	struct list_head head;

	; get alignment based on different type
	if (flags & IORESOURCE_IO) {
		bres = 0;
		min_align = phb->ioda.io_segsize;
		min_balign = 0x1000;
	} else {
		bres = 1;
		min_align = phb->ioda.m32_segsize;
		min_balign = 0x100000;
	}

	; Gather all our children resources ordered by alignment
	INIT_LIST_HEAD(&head);

	; Busses , take care of the child buses
	list_for_each_entry(cbus, &bus->children, node) {
		; calculate the dev_size and dev_align of child bus
		; add to the list from biggest to smallest
		pnv_ioda_calc_bus(cbus, flags, &dev_size, &dev_align);
		pnv_ioda_add_wrap(&head, cbus, NULL, dev_size, dev_align);
	}

	; Devices, assign and calculate resources of devices on current bus 
	list_for_each_entry(cdev, &bus->devices, bus_list) {
		pnv_ioda_calc_dev(cdev, flags, &dev_size, &dev_align);
		; dev_size is the total size of a kind of resource
		; dev_align is the max size of one of it
		/* Align them to segment size */
		if (dev_align < min_align)
			dev_align = min_align;
		pnv_ioda_add_wrap(&head, NULL, cdev, dev_size, dev_align);
		; resource and alignment for a particular pci_dev is added
	}

	if (list_empty(&head))
		goto empty;
	
	; calculate the start
	if (bus->self) {
		/* No offset for downstream bridges */
		; bus->self != NULL means this is not root
		start = 0;
	} else {
		/* Offset from the root */
		; this is the root bus
		if (flags & IORESOURCE_IO)
			/* Don't hand out IO 0 */
			start = hose->io_resource.start + 0x1000;
		else
			start = hose->mem_resources[0].start;
	}

	; now go throught the head list
	while(!list_empty(&head)) {
		w = list_first_entry(&head, struct resource_wrap, link);
		list_del(&w->link);
		if (w->size) {
			if (start) {
				; first align the start based on current alignment
				start = ALIGN(start, w->align);
				; for those dev and bus under bus
				; shift the dev itself
				; or shift the whole bus offset
				if (w->dev)
					pnv_ioda_offset_dev(w->dev,flags,start);
				else if (w->bus)
					pnv_ioda_offset_bus(w->bus,flags,start);
			}
			; set align to the largest one
			; we can improve it here since the head list is ordered
			if (w->align > *align)
				*align = w->align;
		}
		start += w->size;
		kfree(w);
	}

	/* Align and setup bridge resources */
	*align = max_t(resource_size_t, *align,
		       max_t(resource_size_t, min_align, min_balign));
	*size = ALIGN(*size,
		      max_t(resource_size_t, min_align, min_balign));
empty:
	/* Only setup P2P's, not the PHB itself */
	; setup the bridge to contain the resource requirement
	; from its children
	if (bus->self) {
		; means this is not a root bus
		struct resource *res = bus->resource[bres];

		if (WARN_ON(res == NULL))
			return;

		/*
		 * FIXME: We should probably export and call
		 * pci_bridge_check_ranges() to properly re-initialize
		 * the PCI portion of the flags here, and to detect
		 * what the bridge actually supports.
		 */
		; ok, now we will set the resource of the bus.
		; res->start is set to 0, which means it is not allocated
		; res->end is set to the size
		res->start = 0;
		res->flags = (*size) ? flags : 0;
		res->end = (*size) ? (*size - 1) : 0;
	}

2.1.5.3 pnv_ioda_calc_dev(), assign dev resources, get the size and alignment 
===============================================================================
; Calculate resource usage & alignment requirement of a single
; device. This will also assign all resources within the device
; for a given type starting at 0 for the biggest one and then
; assigning in decreasing order of size.
; 
; after return,
; size equal the sum of all size of a certain type of resource
; align equal the max size of a certain type of resource
; Note: this one just calculate the io/mem res for normal device 
;       not touch the bridge resource. IMPORTANT
pnv_ioda_calc_dev(struct pci_dev *dev, unsigned int flags,
		resource_size_t *size, resource_size_t *align)

	; Clear the resources out and mark them all unset 
	for (i = 0; i <= PCI_ROM_RESOURCE; i++) {
		r = &dev->resource[i];
		if (!(r->flags & flags))
		    continue;
		if (r->start) {
			r->end -= r->start; still preserve the size information
			r->start = 0;
		}
		r->flags |= IORESOURCE_UNSET;
	}

	; re-assign certain type of resource from 0
	; from biggest to smallest
	start = 0;
	for (;;) {
		resource_size_t max_size = 0;
		int max_no = -1;

		/* Find next biggest resource */
		for (i = 0; i <= PCI_ROM_RESOURCE; i++) {
			r = &dev->resource[i];
			if (!(r->flags & IORESOURCE_UNSET) ||
			    !(r->flags & flags))
				continue;
			if (resource_size(r) > max_size) {
				max_size = resource_size(r);
				max_no = i;
			}
		}
		if (max_no < 0)
			break;
		r = &dev->resource[max_no];
		if (max_size > *align)
			*align = max_size; align is set to the max size of one of the resource
		*size += max_size;
		r->start = start;
		start += max_size;
		r->end = r->start + max_size - 1;
		r->flags &= ~IORESOURCE_UNSET;
		pr_devel("  ->     R%d %016llx..%016llx\n",
			 max_no, r->start, r->end);
	}

2.1.5.4 pnv_ioda_update_resources(), apply the resouces configuration to HW
===============================================================================
pnv_ioda_update_resources(struct pci_bus *bus)
	struct pci_controller *hose = pci_bus_to_host(bus);

	/* Check if bus resources fit in our IO or M32 range */
	; currently we just use 2 bus->resource[]
	; one for io, one for mem32
	; we need one more for m64
	for (i = 0; bus->self && (i < 2); i++) {
		struct resource *r = bus->resource[i];
		if (r && !pnv_ioda_resource_fit(hose, r))
			pr_err("%s: Bus %d resource %d disabled, no room\n",
			       pci_name(bus->self), bus->number, i);
	}

	/* Update self if it's not a PHB */
	; apply the io/mem limit to hw
	if (bus->self)
		pci_setup_bridge(bus);

	/* Update child devices */
	list_for_each_entry(cdev, &bus->devices, bus_list) {
		/* Check if resource fits, if not, disabled it */
		for (i = 0; i <= PCI_ROM_RESOURCE; i++) {
			struct resource *r = &cdev->resource[i];
			if (!pnv_ioda_resource_fit(hose, r))
				pr_err("%s: Resource %d disabled, no room\n",
				       pci_name(cdev), i);
		}

		/* Assign segments */
		pnv_ioda_setup_pe_segments(cdev);

		/* Update HW BARs */
		; write to the physical BAR
		for (i = 0; i <= PCI_ROM_RESOURCE; i++)
			pci_update_resource(cdev, i);
	}

	/* Update child busses */
	list_for_each_entry(cbus, &bus->children, node)
		pnv_ioda_update_resources(cbus);

2.1.5.4.1 pnv_ioda_resource_fit(), check whether this resource is valid
===============================================================================
; currently we just check m32 and io resouce
; we need to fix it for m64
pnv_ioda_resource_fit(struct pci_controller *hose,
		      struct resource *r)
	struct resource *bounds;

	if (r->flags & IORESOURCE_IO)
		bounds = &hose->io_resource;
	else if (r->flags & IORESOURCE_MEM)
		bounds = &hose->mem_resources[0];
	else
		return 1;

	if (r->start >= bounds->start && r->end <= bounds->end)
		return 1;
	r->flags = 0;
	return 0;
	
2.1.5.4.2 pnv_ioda_setup_pe_segments(), 
===============================================================================
pnv_ioda_setup_pe_segments(struct pci_dev *dev)
	struct pci_controller *hose = pci_bus_to_host(dev->bus);
	struct pnv_phb *phb = hose->private_data;
	struct pci_dn *pdn = pnv_ioda_get_pdn(dev);

	/* Anything not referenced in the device-tree gets PE#0 */
	pe = pdn ? pdn->pe_number : 0;

	struct resource io_res;
	struct resource m32_res;

	/* Calculate the device min/max */
	io_res.start = m32_res.start = (resource_size_t)-1;
	io_res.end = m32_res.end = 0;
	io_res.flags = IORESOURCE_IO;
	m32_res.flags = IORESOURCE_MEM;

	; expand the io_res and m32_res according to the device
	; resource requirement
	for (i = 0; i <= PCI_ROM_RESOURCE; i++) {
		struct resource *r = NULL;
		if (dev->resource[i].flags & IORESOURCE_IO)
			r = &io_res;
		if (dev->resource[i].flags & IORESOURCE_MEM)
			r = &m32_res;
		if (!r)
			continue;
		if (dev->resource[i].start < r->start)
			r->start = dev->resource[i].start;
		if (dev->resource[i].end > r->end)
			r->end = dev->resource[i].end;
	}

	/* Setup IO segments */
	if (io_res.start < io_res.end) {
		pcibios_resource_to_bus(dev, &region, &io_res);
		pos = region.start; this is the pci address?
		i = pos / phb->ioda.io_segsize;
		while(i < phb->ioda.total_pe && pos <= region.end) {
			if (phb->ioda.io_segmap[i]) {
				pr_err("%s: Trying to use IO seg #%d which is"
				       " already used by PE# %d\n",
				       pci_name(dev), i,
				       phb->ioda.io_segmap[i]);
				/* XXX DO SOMETHING TO DISABLE DEVICE ? */
				break;
			}
			phb->ioda.io_segmap[i] = pe; assigne to pe?
			; don't know what it will do
			rc = opal_pci_map_pe_mmio_window(phb->opal_id, pe,
							 OPAL_IO_WINDOW_TYPE,
							 0, i);
			if (rc != OPAL_SUCCESS) {
				pr_err("%s: OPAL error %d setting up mapping"
				       " for IO seg# %d\n",
				       pci_name(dev), rc, i);
				/* XXX DO SOMETHING TO DISABLE DEVICE ? */
				break;
			}
			pos += phb->ioda.io_segsize;
			i++;
		};
	}

	/* Setup M32 segments */
	if (m32_res.start < m32_res.end) {
		pcibios_resource_to_bus(dev, &region, &m32_res);
		pos = region.start;
		i = pos / phb->ioda.m32_segsize;
		while(i < phb->ioda.total_pe && pos <= region.end) {
			if (phb->ioda.m32_segmap[i]) {
				pr_err("%s: Trying to use M32 seg #%d which is"
				       " already used by PE# %d\n",
				       pci_name(dev), i,
				       phb->ioda.m32_segmap[i]);
				/* XXX DO SOMETHING TO DISABLE DEVICE ? */
				break;
			}
			phb->ioda.m32_segmap[i] = pe;
			rc = opal_pci_map_pe_mmio_window(phb->opal_id, pe,
							 OPAL_M32_WINDOW_TYPE,
							 0, i);
			if (rc != OPAL_SUCCESS) {
				pr_err("%s: OPAL error %d setting up mapping"
				       " for M32 seg# %d\n",
				       pci_name(dev), rc, i);
				/* XXX DO SOMETHING TO DISABLE DEVICE ? */
				break;
			}
			pos += phb->ioda.m32_segsize;
			i++;
		}
	}

2.1.6 pcie_bus_configure_settings()
===============================================================================
pcie_bus_configure_settings(struct pci_bus *bus, u8 mpss)
	if (!pci_is_pcie(bus->self))
		return;

	if (pcie_bus_config == PCIE_BUS_TUNE_OFF)
		return;

	if (pcie_bus_config == PCIE_BUS_PEER2PEER)
		smpss = 0;

	if (pcie_bus_config == PCIE_BUS_SAFE) {
		smpss = mpss;

		pcie_find_smpss(bus->self, &smpss);
		pci_walk_bus(bus, pcie_find_smpss, &smpss);
	}

	pcie_bus_configure_set(bus->self, &smpss);
	pci_walk_bus(bus, pcie_bus_configure_set, &smpss);

2.1.6.1 pci_walk_bus(), walk the pci tree and call cb for each pci_dev
===============================================================================
pci_walk_bus(struct pci_bus *top, int (*cb)(struct pci_dev *, void *), void *userdata)
	struct pci_dev *dev;
	struct pci_bus *bus;
	struct list_head *next;

	bus = top;
	down_read(&pci_bus_sem);
	next = top->devices.next;
	for (;;) {
		if (next == &bus->devices) {
			/* end of this bus, go up or finish */
			if (bus == top)
				break;
			next = bus->self->bus_list.next;
			bus = bus->self->bus;
			continue;
		}
		dev = list_entry(next, struct pci_dev, bus_list);
		if (dev->subordinate) {
			/* this is a pci-pci bridge, do its devices next */
			next = dev->subordinate->devices.next;
			bus = dev->subordinate;
		} else
			next = dev->bus_list.next;

		/* Run device routines with the device locked */
		device_lock(&dev->dev);
		retval = cb(dev, userdata);
		device_unlock(&dev->dev);
		if (retval)
			break;
	}
	up_read(&pci_bus_sem);

2.2 pci_bus_add_devices(), breath first go throught the root bus and add devices
===============================================================================
pci_bus_add_devices(struct pci_bus *bus)
	; add newly discovered PCI devices to global device list
	list_for_each_entry(dev, &bus->devices, bus_list) {
		/* Skip already-added devices */
		if (dev->is_added)
			continue;
		retval = pci_bus_add_device(dev);
		if (retval)
			dev_err(&dev->dev, "Error adding device, continuing\n");
	}

	list_for_each_entry(dev, &bus->devices, bus_list) {
		BUG_ON(!dev->is_added);

		child = dev->subordinate;
		/*
		 * If there is an unattached subordinate bus, attach
		 * it and then scan for unattached PCI devices.
		 */
		if (!child)
			continue;
		if (list_empty(&child->node)) {
			down_write(&pci_bus_sem);
			list_add_tail(&child->node, &dev->bus->children);
			up_write(&pci_bus_sem);
		}
		pci_bus_add_devices(child);

		/*
		 * register the bus with sysfs as the parent is now
		 * properly registered.
		 */
		if (child->is_added)
			continue;
		retval = pci_bus_add_child(child);
		if (retval)
			dev_err(&dev->dev, "Error adding bus, continuing\n");
	}

2.3 pcibios_resource_survey()
===============================================================================
pcibios_resource_survey()
	struct pci_bus *b;

	/* Allocate and assign resources */
	list_for_each_entry(b, &pci_root_buses, node)
		; handle bridges
		pcibios_allocate_bus_resources(b);
	; handle normal pci devices
	pcibios_allocate_resources(0);
	pcibios_allocate_resources(1);

	/* Before we start assigning unassigned resource, we try to reserve
	 * the low IO area and the VGA memory area if they intersect the
	 * bus available resources to avoid allocating things on top of them
	 */
	if (!pci_has_flag(PCI_PROBE_ONLY)) {
		list_for_each_entry(b, &pci_root_buses, node)
			pcibios_reserve_legacy_regions(b);
	}

	/* Now, if the platform didn't decide to blindly trust the firmware,
	 * we proceed to assigning things that were left unassigned
	 */
	if (!pci_has_flag(PCI_PROBE_ONLY)) {
		pr_debug("PCI: Assigning unassigned resources...\n");
		pci_assign_unassigned_resources();
	}

	/* Call machine dependent fixup */
	if (ppc_md.pcibios_fixup)
		ppc_md.pcibios_fixup();pnv_pci_ioda_fixup

2.3.1 pcibios_allocate_bus_resources(), this will go through the resources of bridges
===============================================================================
pcibios_allocate_bus_resources(struct pci_bus *bus)
	struct pci_bus *b;
	int i;
	struct resource *res, *pr;

	pr_debug("PCI: Allocating bus resources for %04x:%02x...\n",
		 pci_domain_nr(bus), bus->number);

	pci_bus_for_each_resource(bus, res, i) {
		if (!res || !res->flags || res->start > res->end || res->parent)
			continue;

		/* If the resource was left unset at this point, we clear it */
		if (res->flags & IORESOURCE_UNSET)
			goto clear_resource;

		if (bus->parent == NULL); this is root bus
			pr = (res->flags & IORESOURCE_IO) ?
				&ioport_resource : &iomem_resource;
		else {
			pr = pci_find_parent_resource(bus->self, res);
			if (pr == res) {
				/* this happens when the generic PCI
				 * code (wrongly) decides that this
				 * bridge is transparent  -- paulus
				 */
				continue;
			}
		}

		pr_debug("PCI: %s (bus %d) bridge rsrc %d: %016llx-%016llx "
			 "[0x%x], parent %p (%s)\n",
			 bus->self ? pci_name(bus->self) : "PHB",
			 bus->number, i,
			 (unsigned long long)res->start,
			 (unsigned long long)res->end,
			 (unsigned int)res->flags,
			 pr, (pr && pr->name) ? pr->name : "nil");

		if (pr && !(pr->flags & IORESOURCE_UNSET)) {
			if (request_resource(pr, res) == 0)
				continue;
			/*
			 * Must be a conflict with an existing entry.
			 * Move that entry (or entries) under the
			 * bridge resource and try again.
			 */
			if (reparent_resources(pr, res) == 0)
				continue;
		}
		pr_warning("PCI: Cannot allocate resource region "
			   "%d of PCI bridge %d, will remap\n", i, bus->number);
	clear_resource:
		res->start = res->end = 0;
		res->flags = 0;
	}

	list_for_each_entry(b, &bus->children, node)
		pcibios_allocate_bus_resources(b);

2.3.2 pcibios_allocate_resources(), this will try to assign resource of normal pci device
===============================================================================
pcibios_allocate_resources(int pass)
	struct pci_dev *dev = NULL;
	int idx, disabled;
	u16 command;
	struct resource *r;

	for_each_pci_dev(dev) {
		pci_read_config_word(dev, PCI_COMMAND, &command);
		for (idx = 0; idx <= PCI_ROM_RESOURCE; idx++) {
			r = &dev->resource[idx];
			if (r->parent)		/* Already allocated */
				continue;
			if (!r->flags || (r->flags & IORESOURCE_UNSET))
				continue;	/* Not assigned at all */
			/* We only allocate ROMs on pass 1 just in case they
			 * have been screwed up by firmware
			 */
			if (idx == PCI_ROM_RESOURCE )
				disabled = 1;
			if (r->flags & IORESOURCE_IO)
				disabled = !(command & PCI_COMMAND_IO);
			else
				disabled = !(command & PCI_COMMAND_MEMORY);
			if (pass == disabled)
				alloc_resource(dev, idx);
		}
		if (pass)
			continue;
		r = &dev->resource[PCI_ROM_RESOURCE];
		if (r->flags) {
			/* Turn the ROM off, leave the resource region,
			 * but keep it unregistered.
			 */
			u32 reg;
			pci_read_config_dword(dev, dev->rom_base_reg, &reg);
			if (reg & PCI_ROM_ADDRESS_ENABLE) {
				pr_debug("PCI: Switching off ROM of %s\n",
					 pci_name(dev));
				r->flags &= ~IORESOURCE_ROM_ENABLE;
				pci_write_config_dword(dev, dev->rom_base_reg,
						       reg & ~PCI_ROM_ADDRESS_ENABLE);
			}
		}
	}

2.3.3 pci_assign_unassigned_resources(), resouce assignment
===============================================================================
this function will be called depends on the pci_flags

2.3.4 pnv_pci_ioda_fixup(), resouce assignment
===============================================================================
pnv_pci_ioda_fixup(void)
	pnv_pci_ioda_setup_PEs();
	pnv_pci_ioda_setup_seg();
	pnv_pci_ioda_setup_DMA();

2.3.4.1 pnv_pci_ioda_setup_PEs(), iterate on each root bus, setup PE
===============================================================================
pnv_pci_ioda_setup_PEs(void)
	struct pci_controller *hose, *tmp;

	; go through the hose_list
	list_for_each_entry_safe(hose, tmp, &hose_list, list_node) {
		pnv_ioda_setup_PEs(hose->bus);
	}

2.3.4.2 pnv_pci_ioda_setup_seg(), iterate on each PE 
===============================================================================
pnv_pci_ioda_setup_seg(void)
{
	struct pci_controller *tmp, *hose;
	struct pnv_phb *phb;
	struct pnv_ioda_pe *pe;

	list_for_each_entry_safe(hose, tmp, &hose_list, list_node) {
		phb = hose->private_data;
		list_for_each_entry(pe, &phb->ioda.pe_list, list) {
			pnv_ioda_setup_pe_seg(hose, pe);
		}
	}
}

2.3.4.2 pnv_pci_ioda_setup_DMA(), iterate on each PHB
===============================================================================
pnv_pci_ioda_setup_DMA(void)
{
	struct pci_controller *hose, *tmp;
	struct pnv_phb *phb;

	list_for_each_entry_safe(hose, tmp, &hose_list, list_node) {
		pnv_ioda_setup_dma(hose->private_data);

		/* Mark the PHB initialization done */
		phb = hose->private_data;
		phb->initialized = 1;
	}
}

3. pnv_ioda_setup_PEs(), set up PE
===============================================================================
pnv_ioda_setup_PEs(struct pci_bus *bus)
	struct pci_dev *dev;

	pnv_ioda_setup_bus_PE(bus, 0);

	list_for_each_entry(dev, &bus->devices, bus_list) {
		; go down to its child bus
		if (dev->subordinate) {
			; if it is a PCIe to PCI/PCIX bridge
			if (dev->pcie_type == PCI_EXP_TYPE_PCI_BRIDGE)
				pnv_ioda_setup_bus_PE(dev->subordinate, 1);
			else
			; do it recursively
				pnv_ioda_setup_PEs(dev->subordinate);
		}
	}

3.1 pnv_ioda_setup_bus_PE()
===============================================================================
; bus     on which bus the PE will be
; all     1: the PE will include all buses under bus
          2: the PE will just include this individual bus
pnv_ioda_setup_bus_PE(struct pci_bus *bus, int all)
{
	struct pci_controller *hose = pci_bus_to_host(bus);
	struct pnv_phb *phb = hose->private_data;
	struct pnv_ioda_pe *pe;
	int pe_num;

	; assign a PE number for PE
	pe_num = pnv_ioda_alloc_pe(phb);
	if (pe_num == IODA_INVALID_PE) {
		pr_warning("%s: Not enough PE# available for PCI bus %04x:%02x\n",
			__func__, pci_domain_nr(bus), bus->number);
		return;
	}

	; get the pe representation of struct pnv_ioda_pe
	pe = &phb->ioda.pe_array[pe_num];
	; set the PE flag
	; PNV_IODA_PE_BUS_ALL will cover all the bus under current bus
	; PNV_IODA_PE_BUS     will just cover current bus
	pe->flags = (all ? PNV_IODA_PE_BUS_ALL : PNV_IODA_PE_BUS);
	pe->pbus = bus;
	pe->pe_number = pe_num;
	pe->pdev = NULL;
	pe->tce32_seg = -1;
	pe->mve_number = -1;
	pe->rid = bus->secondary << 8;
	pe->dma_weight = 0;

	if (all)
		pe_info(pe, "Secondary busses %d..%d associated with PE#%d\n",
			bus->secondary, bus->subordinate, pe_num);
	else
		pe_info(pe, "Secondary busses %d associated with PE#%d\n",
			bus->secondary, pe_num);

	if (pnv_ioda_configure_pe(phb, pe)) {
		/* XXX What do we do here ? */
		if (pe_num)
			pnv_ioda_free_pe(phb, pe_num);
		pe->pbus = NULL;
		return;
	}

	/* Associate it with all child devices */
	pnv_ioda_setup_same_PE(bus, pe);

	/* Put PE to the list */
	list_add_tail(&pe->list, &phb->ioda.pe_list);

	/* Account for one DMA PE if at least one DMA capable device exist
	 * below the bridge
	 */
	if (pe->dma_weight != 0) {
		phb->ioda.dma_weight += pe->dma_weight;
		phb->ioda.dma_pe_count++;
	}

	/* Link the PE */
	pnv_ioda_link_pe_by_weight(phb, pe);
}

3.1.1 pnv_ioda_configure_pe()
===============================================================================
pnv_ioda_configure_pe(struct pnv_phb *phb,
					   struct pnv_ioda_pe *pe)
{
	struct pci_dev *parent;
	uint8_t bcomp, dcomp, fcomp;
	long rc, rid_end, rid;

	/* Bus validation ? */
	; this is a bus PE
	if (pe->pbus) {
		int count;

		; do not match device and function
		dcomp = OPAL_IGNORE_RID_DEVICE_NUMBER;
		fcomp = OPAL_IGNORE_RID_FUNCTION_NUMBER;
		; parent point to the bridge which pbus attachs
		parent = pe->pbus->self;
		if (pe->flags & PNV_IODA_PE_BUS_ALL)
			count = pe->pbus->subordinate - pe->pbus->secondary + 1;
		else
			count = 1;

		switch(count) {
		case  1: bcomp = OpalPciBusAll;		break;
		case  2: bcomp = OpalPciBus7Bits;	break;
		case  4: bcomp = OpalPciBus6Bits;	break;
		case  8: bcomp = OpalPciBus5Bits;	break;
		case 16: bcomp = OpalPciBus4Bits;	break;
		case 32: bcomp = OpalPciBus3Bits;	break;
		default:
			pr_err("%s: Number of subordinate busses %d"
			       " unsupported\n",
			       pci_name(pe->pbus->self), count);
			/* Do an exact match only */
			bcomp = OpalPciBusAll;
		}
		rid_end = pe->rid + (count << 8);
	} else {
	; this is an individual PE
		; parent point to the bridge which the device attachs
		parent = pe->pdev->bus->self;
		bcomp = OpalPciBusAll;
		dcomp = OPAL_COMPARE_RID_DEVICE_NUMBER;
		fcomp = OPAL_COMPARE_RID_FUNCTION_NUMBER;
		rid_end = pe->rid + 1;
	}

	/* Associate PE in PELT */
	rc = opal_pci_set_pe(phb->opal_id, pe->pe_number, pe->rid,
			     bcomp, dcomp, fcomp, OPAL_MAP_PE);
	if (rc) {
		pe_err(pe, "OPAL error %ld trying to setup PELT table\n", rc);
		return -ENXIO;
	}
	opal_pci_eeh_freeze_clear(phb->opal_id, pe->pe_number,
				  OPAL_EEH_ACTION_CLEAR_FREEZE_ALL);

	/* Add to all parents PELT-V */
	; which means ?
	while (parent) {
		struct pci_dn *pdn = pnv_ioda_get_pdn(parent);
		if (pdn && pdn->pe_number != IODA_INVALID_PE) {
			rc = opal_pci_set_peltv(phb->opal_id, pdn->pe_number,
						pe->pe_number, OPAL_ADD_PE_TO_DOMAIN);
			/* XXX What to do in case of error ? */
		}
		parent = parent->bus->self;
	}
	/* Setup reverse map */
	for (rid = pe->rid; rid < rid_end; rid++)
		phb->ioda.pe_rmap[rid] = pe->pe_number;

	/* Setup one MVTs on IODA1 */
	if (phb->type == PNV_PHB_IODA1) {
		pe->mve_number = pe->pe_number;
		rc = opal_pci_set_mve(phb->opal_id, pe->mve_number,
				      pe->pe_number);
		if (rc) {
			pe_err(pe, "OPAL error %ld setting up MVE %d\n",
			       rc, pe->mve_number);
			pe->mve_number = -1;
		} else {
			rc = opal_pci_set_mve_enable(phb->opal_id,
						     pe->mve_number, OPAL_ENABLE_MVE);
			if (rc) {
				pe_err(pe, "OPAL error %ld enabling MVE %d\n",
				       rc, pe->mve_number);
				pe->mve_number = -1;
			}
		}
	} else if (phb->type == PNV_PHB_IODA2)
		pe->mve_number = 0;

	return 0;
}

3.1.2 pnv_ioda_setup_same_PE(), pci device on the same bus with the same PE#
===============================================================================
pnv_ioda_setup_same_PE(struct pci_bus *bus, struct pnv_ioda_pe *pe)
{
	struct pci_dev *dev;

	; go throught pci devices of the same bus
	list_for_each_entry(dev, &bus->devices, bus_list) {
		struct pci_dn *pdn = pnv_ioda_get_pdn(dev);

		if (pdn == NULL) {
			pr_warn("%s: No device node associated with device !\n",
				pci_name(dev));
			continue;
		}
		pci_dev_get(dev);
		pdn->pcidev = dev;
		pdn->pe_number = pe->pe_number;
		pe->dma_weight += pnv_ioda_dma_weight(dev);
		; go down to child if this PE is PNV_IODA_PE_BUS_ALL
		if ((pe->flags & PNV_IODA_PE_BUS_ALL) && dev->subordinate)
			pnv_ioda_setup_same_PE(dev->subordinate, pe);
	}
}

3.1.3 pnv_ioda_link_pe_by_weight()
===============================================================================
pnv_ioda_link_pe_by_weight(struct pnv_phb *phb,
						 struct pnv_ioda_pe *pe)
{
	struct pnv_ioda_pe *lpe;

	list_for_each_entry(lpe, &phb->ioda.pe_dma_list, dma_link) {
		if (lpe->dma_weight < pe->dma_weight) {
			list_add_tail(&pe->dma_link, &lpe->dma_link);
			return;
		}
	}
	list_add_tail(&pe->dma_link, &phb->ioda.pe_dma_list);
}

4. pnv_ioda_setup_pe_seg(), setup the mmio window
===============================================================================
pnv_ioda_setup_pe_seg(struct pci_controller *hose,
				struct pnv_ioda_pe *pe)
{
	struct pnv_phb *phb = hose->private_data;
	struct pci_bus_region region;
	struct resource *res;
	int i, index;
	int rc;

	/*
	 * NOTE: We only care PCI bus based PE for now. For PCI
	 * device based PE, for example SRIOV sensitive VF should
	 * be figured out later.
	 */
	; we need to do some change
	BUG_ON(!(pe->flags & (PNV_IODA_PE_BUS | PNV_IODA_PE_BUS_ALL)));

	pci_bus_for_each_resource(pe->pbus, res, i) {
		if (!res || !res->flags ||
		    res->start > res->end)
			continue;

		if (res->flags & IORESOURCE_IO) {
			region.start = res->start - phb->ioda.io_pci_base;
			region.end   = res->end - phb->ioda.io_pci_base;
			index = region.start / phb->ioda.io_segsize;

			while (index < phb->ioda.total_pe &&
			       region.start <= region.end) {
				phb->ioda.io_segmap[index] = pe->pe_number;
				rc = opal_pci_map_pe_mmio_window(phb->opal_id,
					pe->pe_number, OPAL_IO_WINDOW_TYPE, 0, index);
				if (rc != OPAL_SUCCESS) {
					pr_err("%s: OPAL error %d when mapping IO "
					       "segment #%d to PE#%d\n",
					       __func__, rc, index, pe->pe_number);
					break;
				}

				region.start += phb->ioda.io_segsize;
				index++;
			}
		} else if (res->flags & IORESOURCE_MEM) {
			region.start = res->start -
				       hose->pci_mem_offset -
				       phb->ioda.m32_pci_base;
			region.end   = res->end -
				       hose->pci_mem_offset -
				       phb->ioda.m32_pci_base;
			index = region.start / phb->ioda.m32_segsize;

			while (index < phb->ioda.total_pe &&
			       region.start <= region.end) {
				phb->ioda.m32_segmap[index] = pe->pe_number;
				rc = opal_pci_map_pe_mmio_window(phb->opal_id,
					pe->pe_number, OPAL_M32_WINDOW_TYPE, 0, index);
				if (rc != OPAL_SUCCESS) {
					pr_err("%s: OPAL error %d when mapping M32 "
					       "segment#%d to PE#%d",
					       __func__, rc, index, pe->pe_number);
					break;
				}

				region.start += phb->ioda.m32_segsize;
				index++;
			}
		}
	}
}

5. pnv_ioda_setup_dma(), setup the DMA for each PHB
===============================================================================
pnv_ioda_setup_dma(struct pnv_phb *phb)
{
	struct pci_controller *hose = phb->hose;
	unsigned int residual, remaining, segs, tw, base;
	struct pnv_ioda_pe *pe;

	/* If we have more PE# than segments available, hand out one
	 * per PE until we run out and let the rest fail. If not,
	 * then we assign at least one segment per PE, plus more based
	 * on the amount of devices under that PE
	 */
	; tce count would be different from PE#?
	if (phb->ioda.dma_pe_count > phb->ioda.tce32_count)
		residual = 0;
	else
		residual = phb->ioda.tce32_count -
			phb->ioda.dma_pe_count;

	pr_info("PCI: Domain %04x has %ld available 32-bit DMA segments\n",
		hose->global_number, phb->ioda.tce32_count);
	pr_info("PCI: %d PE# for a total weight of %d\n",
		phb->ioda.dma_pe_count, phb->ioda.dma_weight);

	/* Walk our PE list and configure their DMA segments, hand them
	 * out one base segment plus any residual segments based on
	 * weight
	 */
	remaining = phb->ioda.tce32_count;
	tw = phb->ioda.dma_weight;
	base = 0;
	list_for_each_entry(pe, &phb->ioda.pe_dma_list, dma_link) {
		if (!pe->dma_weight)
			continue;
		if (!remaining) {
			pe_warn(pe, "No DMA32 resources available\n");
			continue;
		}
		segs = 1;
		if (residual) {
			segs += ((pe->dma_weight * residual)  + (tw / 2)) / tw;
			if (segs > remaining)
				segs = remaining;
		}
		pe_info(pe, "DMA weight %d, assigned %d DMA32 segments\n",
			pe->dma_weight, segs);
		pnv_pci_ioda_setup_dma_pe(phb, pe, base, segs);
		remaining -= segs;
		base += segs;
	}
}

5.1 pnv_pci_ioda_setup_dma_pe(), 
===============================================================================
; base      is the segment base index
; segs      is the number of segments assign to pe
pnv_pci_ioda_setup_dma_pe(struct pnv_phb *phb,
						struct pnv_ioda_pe *pe,
						unsigned int base,
						unsigned int segs)
{

	struct page *tce_mem = NULL;
	const __be64 *swinvp;
	struct iommu_table *tbl;
	unsigned int i;
	int64_t rc;
	void *addr;

	/* 256M DMA window, 4K TCE pages, 8 bytes TCE */
#define TCE32_TABLE_SIZE	((0x10000000 / 0x1000) * 8)

	/* XXX FIXME: Handle 64-bit only DMA devices */
	/* XXX FIXME: Provide 64-bit DMA facilities & non-4K TCE tables etc.. */
	/* XXX FIXME: Allocate multi-level tables on PHB3 */

	/* We shouldn't already have a 32-bit DMA associated */
	if (WARN_ON(pe->tce32_seg >= 0))
		return;

	/* Grab a 32-bit TCE table */
	pe->tce32_seg = base;
	pe_info(pe, " Setting up 32-bit TCE table at %08x..%08x\n",
		(base << 28), ((base + segs) << 28) - 1);

	/* XXX Currently, we allocate one big contiguous table for the
	 * TCEs. We only really need one chunk per 256M of TCE space
	 * (ie per segment) but that's an optimization for later, it
	 * requires some added smarts with our get/put_tce implementation
	 */
	tce_mem = alloc_pages_node(phb->hose->node, GFP_KERNEL,
				   get_order(TCE32_TABLE_SIZE * segs));
	if (!tce_mem) {
		pe_err(pe, " Failed to allocate a 32-bit TCE memory\n");
		goto fail;
	}
	addr = page_address(tce_mem);
	memset(addr, 0, TCE32_TABLE_SIZE * segs);

	/* Configure HW */
	for (i = 0; i < segs; i++) {
		rc = opal_pci_map_pe_dma_window(phb->opal_id,
					      pe->pe_number,
					      base + i, 1,
					      __pa(addr) + TCE32_TABLE_SIZE * i,
					      TCE32_TABLE_SIZE, 0x1000);
		if (rc) {
			pe_err(pe, " Failed to configure 32-bit TCE table,"
			       " err %ld\n", rc);
			goto fail;
		}
	}

	/* Setup linux iommu table */
	tbl = &pe->tce32_table;
	pnv_pci_setup_iommu_table(tbl, addr, TCE32_TABLE_SIZE * segs,
				  base << 28);

	/* OPAL variant of P7IOC SW invalidated TCEs */
	swinvp = of_get_property(phb->hose->dn, "ibm,opal-tce-kill", NULL);
	if (swinvp) {
		/* We need a couple more fields -- an address and a data
		 * to or.  Since the bus is only printed out on table free
		 * errors, and on the first pass the data will be a relative
		 * bus number, print that out instead.
		 */
		tbl->it_busno = 0;
		tbl->it_index = (unsigned long)ioremap(be64_to_cpup(swinvp), 8);
		tbl->it_type = TCE_PCI_SWINV_CREATE | TCE_PCI_SWINV_FREE
			| TCE_PCI_SWINV_PAIR;
	}
	iommu_init_table(tbl, phb->hose->node);

	if (pe->pdev)
		set_iommu_table_base(&pe->pdev->dev, tbl);
	else
		pnv_ioda_setup_bus_dma(pe, pe->pbus);

	return;
 fail:
	/* XXX Failure: Try to fallback to 64-bit only ? */
	if (pe->tce32_seg >= 0)
		pe->tce32_seg = -1;
	if (tce_mem)
		__free_pages(tce_mem, get_order(TCE32_TABLE_SIZE * segs));
}

5.2 pnv_pci_setup_iommu_table(), 
===============================================================================
pnv_pci_setup_iommu_table(struct iommu_table *tbl,
			       void *tce_mem, u64 tce_size,
			       u64 dma_offset)
{
	tbl->it_blocksize = 16;
	tbl->it_base = (unsigned long)tce_mem;
	tbl->it_offset = dma_offset >> IOMMU_PAGE_SHIFT;
	tbl->it_index = 0;
	tbl->it_size = tce_size >> 3;
	tbl->it_busno = 0;
	tbl->it_type = TCE_PCI;
}

5.3 iommu_init_table(), 
===============================================================================
iommu_table *iommu_init_table(struct iommu_table *tbl, int nid)
{
	unsigned long sz;
	static int welcomed = 0;
	struct page *page;

	/* Set aside 1/4 of the table for large allocations. */
	tbl->it_halfpoint = tbl->it_size * 3 / 4;

	/* number of bytes needed for the bitmap */
	sz = (tbl->it_size + 7) >> 3;

	page = alloc_pages_node(nid, GFP_ATOMIC, get_order(sz));
	if (!page)
		panic("iommu_init_table: Can't allocate %ld bytes\n", sz);
	tbl->it_map = page_address(page);
	memset(tbl->it_map, 0, sz);

	/*
	 * Reserve page 0 so it will not be used for any mappings.
	 * This avoids buggy drivers that consider page 0 to be invalid
	 * to crash the machine or even lose data.
	 */
	if (tbl->it_offset == 0)
		set_bit(0, tbl->it_map);

	tbl->it_hint = 0;
	tbl->it_largehint = tbl->it_halfpoint;
	spin_lock_init(&tbl->it_lock);

	iommu_table_clear(tbl);

	if (!welcomed) {
		printk(KERN_INFO "IOMMU table initialized, virtual merging %s\n",
		       novmerge ? "disabled" : "enabled");
		welcomed = 1;
	}

	return tbl;
}

6. machine type initialization, setup the ppc_md structure based on the machine type
===============================================================================
define_machine(powernv) {
	.name			= "PowerNV",
	.probe			= pnv_probe,
	.init_early		= pnv_init_early,
	.setup_arch		= pnv_setup_arch,
	.init_IRQ		= pnv_init_IRQ,
	.show_cpuinfo		= pnv_show_cpuinfo,
	.progress		= pnv_progress,
	.power_save             = power7_idle,
	.calibrate_decr		= generic_calibrate_decr,
#ifdef CONFIG_KEXEC
	.kexec_cpu_down		= pnv_kexec_cpu_down,
#endif
};

And this structure is stored in struct machdep_calls ppc_md;
And when boot up, this machdep_calls is copied in probe_machine();

head_64.S
	early_setup
		probe_machine()
			go throught the __machine_desc_start and __machine_desc_end
			machine type is defined by define_machine, and stored in 
			this area by vmlinux.lds.S

			ppc_md.probe(); if match return 1

7. device tree parse in prom_init()
===============================================================================
prom_init.c
	prom_init_client_services();
	prom_find_mmu();
	prom_init_stdout();
	of_platform = prom_find_machine_type(); may return PLATFORM_PSERIES or PLATFORM_OPAL
	prom_check_initrd();
	early_cmdline_parse();
	prom_init_mem();
	prom_find_boot_cpu();
	prom_check_displays();
	prom_initialize_tce_table(); this is done only on PLATFORM_PSERIES
	prom_instantiate_rtas(); not on PLATFORM_OPAL
	; on PPC_POWERNV
	prom_instantiate_opal(); and some other stuff

	flatten_device_tree();
		build header
		build strings
		build structure

	hdr = RELOC(dt_header_start);
	__start(hdr, kbase, 0, 0, 0, 0, 0); call kernel again

second round of __start()
	__start_initialization_multiplatform()
		enable_64b_mode
		relative_toc
		__mmu_off
		__after_prom_start
			...
			start_here_multiplatform();
				early_setup(); setup_64.c
					early_init_devtree();
					probe_machine();
				start_here_common
					setup_system
					start_kernel

8. pcibios_fixup_resources(), mark the resource of a new pci device as IORESOURCE_UNSET
===============================================================================
This function is called by pci_device_add(). 

pcibios_fixup_resources(struct pci_dev *dev)
{
	struct pci_controller *hose = pci_bus_to_host(dev->bus);
	int i;

	if (!hose) {
		printk(KERN_ERR "No host bridge for PCI dev %s !\n",
		       pci_name(dev));
		return;
	}
	for (i = 0; i < DEVICE_COUNT_RESOURCE; i++) {
		struct resource *res = dev->resource + i;
		if (!res->flags)
			continue;

		/* If we're going to re-assign everything, we mark all resources
		 * as unset (and 0-base them). In addition, we mark BARs starting
		 * at 0 as unset as well, except if PCI_PROBE_ONLY is also set
		 * since in that case, we don't want to re-assign anything
		 */
		if (pci_has_flag(PCI_REASSIGN_ALL_RSRC) ||
		    (res->start == 0 && !pci_has_flag(PCI_PROBE_ONLY))) {
			/* Only print message if not re-assigning */
			if (!pci_has_flag(PCI_REASSIGN_ALL_RSRC))
				pr_debug("PCI:%s Resource %d %016llx-%016llx [%x] "
					 "is unassigned\n",
					 pci_name(dev), i,
					 (unsigned long long)res->start,
					 (unsigned long long)res->end,
					 (unsigned int)res->flags);
			res->end -= res->start;
			res->start = 0;
			res->flags |= IORESOURCE_UNSET;
			continue;
		}

		pr_debug("PCI:%s Resource %d %016llx-%016llx [%x]\n",
			 pci_name(dev), i,
			 (unsigned long long)res->start,\
			 (unsigned long long)res->end,
			 (unsigned int)res->flags);
	}

	/* Call machine specific resource fixup */
	if (ppc_md.pcibios_fixup_resources)
		ppc_md.pcibios_fixup_resources(dev);
}
DECLARE_PCI_FIXUP_HEADER(PCI_ANY_ID, PCI_ANY_ID, pcibios_fixup_resources);
