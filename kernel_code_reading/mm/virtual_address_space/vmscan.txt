1. kswapd_init()
================================================================================
static int __init kswapd_init(void)
{
	int nid, ret;

	swap_setup();
	for_each_node_state(nid, N_MEMORY)
 		kswapd_run(nid);
	ret = cpuhp_setup_state_nocalls(CPUHP_AP_ONLINE_DYN,
					"mm/vmscan:online", kswapd_cpu_online,
					NULL);
	WARN_ON(ret < 0);
	return 0;
}

1.1 kswapd_run(), for each numa node
================================================================================
int kswapd_run(int nid)
{
	pg_data_t *pgdat = NODE_DATA(nid);
	int ret = 0;

	if (pgdat->kswapd)
		return 0;

	pgdat->kswapd = kthread_run(kswapd, pgdat, "kswapd%d", nid);
	if (IS_ERR(pgdat->kswapd)) {
		/* failure at boot is fatal */
		BUG_ON(system_state < SYSTEM_RUNNING);
		pr_err("Failed to start kswapd on node %d\n", nid);
		ret = PTR_ERR(pgdat->kswapd);
		pgdat->kswapd = NULL;
	}
	return ret;
}

1.2 kswapd_cpu_online(), set kswapd cpu affinity
================================================================================

2. kswapd()
================================================================================
2.1 set_cpus_allowed_ptr()
================================================================================
2.2 set_freezable()
================================================================================
2.3 kswapd_try_to_sleep()
================================================================================
2.3.1 prepare_to_wait(, TASK_INTERRUPTIBLE)
================================================================================
2.3.2 prepare_kswapd_sleep(pgdat, reclaim_order, classzone_idx), return true if kswapd is ready to sleep
================================================================================
2.3.2.1 pgdat_balanced(pgdat, reclaim_order, classzone_idx)
================================================================================
2.3.2.2 clear_pgdat_congested(pgdat)
================================================================================
2.3.3 reset_isolation_suitable(pgtad)
================================================================================
2.3.3.1 __reset_isolation_suitable(zone), clear migrate_skip and calculate zon->compact_*
================================================================================
2.3.3.1.1 __reset_isolation_pfn(zone, pfn, check_source, check_target);
================================================================================
2.3.4 wakeup_kcompactd(pgdat, alloc_order, classzone_idx)
================================================================================
2.3.4.1 wake_up_interruptible(&pgdat->kcompactd_wait)
================================================================================
2.3.5 schedule_timeout(HZ/10), sleep till timeout
================================================================================
2.3.6 finish_wait()
================================================================================
2.3.7 prepare_to_wait()
================================================================================
2.3.8 prepare_kswapd_sleep(), real sleep till woken up by others
================================================================================
2.4 balance_pgdat()
================================================================================
2.4.1 age_active_anon(pgdat, sc), move some page from active to inactive
================================================================================
2.4.1.1 inactive_is_low(lruvec, LRU_INACTIVE_ANON)
================================================================================
2.4.1.2 shrink_active_list(SWAP_CLUSTER_MAX, lruvec, sc, LRU_ACTIVE_ANON)
================================================================================
2.4.2 mem_cgroup_soft_limit_reclaim()
================================================================================
2.4.2.1 mctz = soft_limit_tree_node()
================================================================================
2.4.2.2 mz = mem_cgroup_largest_soft_limit_node(mctz)
================================================================================
2.4.2.3 mem_cgroup_soft_limit_reclaim(mz->memcg, pgdat, )
================================================================================
2.4.3 kswapd_shrink_node(pgdat, &sc)
================================================================================
2.4.3.1 sc->nr_to_reclaim = 0 
================================================================================
2.4.3.2 sc->nr_to_reclaim += max(high_wmark_pages(zone), SWAP_CLUSTER_MAX)
================================================================================
2.4.3.3 shrink_node(pgdat, sc)
================================================================================
2.4.3.4 return sc->nr_scanned >= sc->nr_to_reclaim
================================================================================
2.4.4 allow_direct_reclaim(pgdat)
================================================================================
2.4.4.1 pfmemalloc_reserve += min_wmark_pages(zon)
================================================================================
2.4.4.2 free_pages += zone_pages_state(zone, NR_FREE_PAGES)
================================================================================
2.4.4.3 return free_pages > pfmemalloc_reserve / 2
================================================================================
2.4.5 wake_up_all(&pgdat->pfmemalloc_wait)
================================================================================

3. pgdat_balanced(pgdat, order, classzone_idx), more free_pages than WMHIGH
================================================================================
3.1 mark = high_wmark_pages(zone)
================================================================================
3.2 zone_watermark_ok_safe(zone, order, mark, classzone_idx)
================================================================================
3.2.1 free_pages = zone_page_state(zone, NR_FREE_PAGES)
================================================================================
3.2.2 free_pages = zone_page_state_snapshot(zone, NR_FREE_PAGES)
================================================================================
3.2.3 __zone_watermark_ok(zone, order, mark, classzone_idx, alloc_flags, free_pages)
================================================================================

4. shrink_node(pgdat, sc)
================================================================================
4.1 target_lruvec = mem_cgroup_lruvec(sc->target_mem_cgroup, pgdat)
================================================================================
4.2 nr_reclaimed = sc->nr_reclaimed
================================================================================
4.3 memset(&sc->nr, 0, sizeof())
================================================================================
4.4 shrink_node_memcgs(pgdat, sc)
================================================================================
4.4.1 target_memcg = sc->target_mem_cgroup
================================================================================
4.4.2 memcg = mem_cgroup_iter(target_memcg, NULL, NULL)
================================================================================
4.4.3 lruvec = mem_cgroup_lruvec(memcg, pgdat)
================================================================================
4.4.4 shrink_lruvec(lruvec, sc)
================================================================================
4.4.4.1 get_scan_count(lruvec, sc, nr), calc scan count affected by priority
================================================================================
4.4.4.2 while (nr[LRU_INACTIVE_ANON] || nr[LRU_ACTIVE_FILE] || nr[LRU_INACTIVE_FILE]) 
================================================================================
4.4.4.3 shrink_list(lru, nr_to_scan, lruvec, sc), do reclaim
================================================================================
4.4.5 shrink_slab()
================================================================================
4.4.6 vmpressure(gfp_mask, memcg, false, scanned, reclaimed)
================================================================================
4.4.7 memcg = mem_cgroup_iter(target_memcg, memcg, NULL)
================================================================================
4.5 vmpressure(gfp, sc->target_mem_cgroup, tree, scanned, reclaimed), account vm pressure
================================================================================
4.6 reclaimable = true if sc->nr_reclaimed - nr_reclaimed
================================================================================
4.7 should_continue_reclaim()
================================================================================
4.7.1 compaction_suitable(zone, order, 0, idx)
================================================================================
4.7.2 pages_for_compaction = compact_gap(sc->order)
================================================================================
4.7.2.1 return 2UL << order;
================================================================================
4.7.3 return inactive_lru_pages > pages_for_compaction
================================================================================
4.8 return reclaimable
================================================================================

5. shrink_list(lru, nr_to_scan, lruvec, sc), do reclaim
================================================================================
5.1 shrink_active_list()
================================================================================
5.1.1 spin_lock_irq(&pgdat->lru_lock)
================================================================================
5.1.2 isolate_lru_pages(, &l_hold, &nr_scanned, sc, lru), isolate page to l_hold
================================================================================
5.1.2.1 skip page above sc.reclaim_idx
================================================================================
5.1.2.2 __isolate_lru_page(page, mode), remove page from its LRU
================================================================================
5.1.2.2.1 ClearPageLRU(page)
================================================================================
5.1.2.3 list_move(&page->lru, dst)
================================================================================
5.1.3 spin_unlock_irq(&pgdat->lru_lock)
================================================================================
5.1.4 page = lru_to_page(&l_hold)
================================================================================
5.1.5 list_del(&page->lru), take a page from l_hold
================================================================================
5.1.6 putback_lru_page(page) if !page_evictable()
================================================================================
5.1.7 list_add(&page->lru, &l_active) if page_referenced(), test accessed bit
================================================================================
5.1.8 list_add(&page->lru, &l_inactive)
================================================================================
5.1.9 spin_lock_irq(&pgdat->lru_lock)
================================================================================
5.1.10 move_pages_to_lru(lruvec, &l_active), depenends on PageActive
================================================================================
5.1.10.1 putback_lru_page(page), if !page_evictable()
================================================================================
5.1.10.1.1 lru_cache_add(page)
================================================================================
5.1.10.2 SetPageLRU(page)
================================================================================
5.1.10.3 lru = page_lru(page)
================================================================================
5.1.10.4 list_move(&page->lru, &lruvec->lists[lru])
================================================================================
5.1.10.5 if put_page_testzero()
================================================================================
5.1.10.6 del_page_from_lru_list(page, lruvec, lru)
================================================================================
5.1.11 move_pages_to_lru(lruvec, &l_inactive)
================================================================================
5.1.12 list_splice(&l_inactive, &l_active)
================================================================================
5.1.13 spin_unlock_irq(&pgdat->lru_lock)
================================================================================
5.1.14 free_unref_page_list(&l_active)
================================================================================
5.2 shrink_inactive_list(nr_to_scan, lruvec, sc, lru), return # pages reclaimed
================================================================================
5.2.1 too_many_isolated(pgdat, file, sc)
================================================================================
5.2.2 lru_add_drain()
================================================================================
5.2.3 isolate_lru_pages(nr_to_scan, lruvec, &page_list, &nr_scanned, sc, lru)
================================================================================
5.2.4 nr_reclaimed = shrink_page_list(&page_list, pgdat, sc, 0, &stat, false), core function
================================================================================
5.2.4.1 memset(stat, 0, sizeof(*stat))
================================================================================
5.2.4.2 page = lru_to_page(page_list)
================================================================================
5.2.4.3 list_del(&page->lru)
================================================================================
5.2.4.4 trylock_page(page)
================================================================================
5.2.4.5 page_check_dirty_writeback(page, &dirty, &writeback)
================================================================================
5.2.4.6 references = page_check_references(page, sc)
================================================================================
5.2.4.7 __remove_mapping(mapping, page, true, ), remove from swapcache or pagecache
================================================================================
5.2.4.1 list_add(&page->lru, &ret_pages)
================================================================================
5.2.4.1 free_unref_page_list(&free_pages)
================================================================================
5.2.4.1 list_splice(&ret_pages, page_list)
================================================================================
5.2.5 move_pages_to_lru()
================================================================================
5.2.6 free_unref_page_list()
================================================================================

0. data structure
================================================================================

0.1 pageblock_flags
================================================================================
The data stored here is enum migratetype.

   mem_section->usage->pageblock_flags[usemap_size()]
   NR_PAGEBLOCK_BITS = 4
   +----------------------------+
   |                            |
   |                            |
   +----------------------------+

0.2 pgdat
================================================================================

   pgdat
   +-------------------------------+
   |kswapd_order                   |
   |kswapd_classzone_idx           |
   |                               |
   +-------------------------------+
   |node_zones                     |
   |    (struct zone)              |
   |    +--------------------------+
   |    |compact_init_migrate_pfn  |
   |    |compact_cached_migrate_pfn|
   |    |                          |
   |    |compact_init_free_pfn     |
   |    |compact_cached_free_pfn   |
   |    |                          |
   |    |_watermark[NR_WMARK]      |  WMARK_MIN|LOW|HIGH
   |    |watermark_boost           |  init to 0 or set in boost_watermark()
   |    |                          |
   |    |lowmem_reserve[MAX_ZONES] |
   |    |                          |
   |    |vm_stat[]                 | NR_VM_ZONE_STAT_ITEMS
   |    |   (atomic_long_t)        |
   |    |                          |
   +----+--------------------------+
   |vm_stat[NR_VM_NODE_STAT_ITEMS] |
   |    (atomic_long_t)            |
   |                               |
   +-------------------------------+

0.2.1 node_page_state(pgdat, item)
================================================================================
return x = atomic_long_read(&pgdat->vm_stat[item]);

0.2.2 zone_page_state(zone, item)
================================================================================
return x = atomic_long_read(&zone->vm_stat[item]);

0.3 __setup_per_zone_wmarks()
================================================================================

0.3.1 WMARK_MIN
================================================================================
lowmem_pages = sum(zone_managed_pages)
_watermark[WMARK_MIN] = pages_min * (zone_managed_pages / lowmem_pages)

=>

sum(_watermark[WMARK_MIN]) = pages_min

The summation of all WMARK_MIN is pages_min.


0.3.2 WMARK_LOW|HIGH
================================================================================

     +-------------+
     |             |
     .             .
     |             |
     |             |
     +-------------+ WMARK_HIGH -+-
     |             |             ^
     |             |             d
     |             |             v
     +-------------+ WMARK_LOW  -+-
     |             |             ^
     |             |             d
     |             |             v
     +-------------+ WMARK_MIN  -+-
     |             |
     |             |
     |             |
     +-------------+

The distance between HIGH and LOW is the same as LOW and MIN, which is d here.

d = (MIN / 4) or (part of zone_managed_pages) 


0.4 setup_per_zone_lowmem_reserve()
================================================================================
    Zone0              Zone1              Zone2

    lowmem_reserve[]   lowmem_reserve[]   lowmem_reserve[]
    +-------------+    +-------------+    +-------------+
    |for 1 & 2    |    |for 2        |    |0            |
    +-------------+    +-------------+    +-------------+
    |for 1        |    |0            |    |0            |
    +-------------+    +-------------+    +-------------+
    |0            |    |0            |    |0            |
    +-------------+    +-------------+    +-------------+

For example:

Zone1.lowmem_reserve[2] = zone_managed_pages(Zone2) / ratio

Zone0.lowmem_reserve[2] = zone_managed_pages(Zone1 + Zone2) / ratio

0.5 scan_control
================================================================================

   scan_control
   +-------------------------------+
   |nodemask                       |
   |    (nodemask_t*)              |
   |target_mem_cgroup              |
   |    (mem_cgroup *)             |
   +-------------------------------+
   |may_deactivate:2               |
   |force_deactivate:2             |
   |skipped_deactivate:2           |
   |may_writepage:1                |
   |may_unmap:1                    |
   |may_swap:1                     |
   |memcg_low_reclaim:1            |
   |memcg_low_skipped:1            |
   |hibernation_mode:1             |
   |compaction_ready:1             |
   |cache_trim_mode:1              |
   |file_is_tiny:1                 |
   |                               |
   +-------------------------------+
   |order                          |
   |priorit                        |
   |reclaim_idx                    |
   |    (s8)                       |
   |nr_scanned                     |
   |nr_reclaimed                   |
   |nr_to_reclaim                  |
   |    (unsigned long)            |
   |nr                             |
   |    +--------------------------+
   |    |dirty                     |
   |    |unqueued_dirty            |
   |    |congested                 |
   |    |writeback                 |
   |    |immediate                 |
   |    |file_taken                |
   |    |taken                     |
   |    +--------------------------+
   |reclaim_state                  |
   |    (struct reclaim_state)     |
   |    +--------------------------+
   |    |reclaimed_slab            |
   |    +--------------------------+
   |                               |
   |                               |
   +-------------------------------+

0.6 lruvec
================================================================================
recent_scanned/recent_rotated is updated during shrink_inactive_list().

   lruvec
   +-------------------------------+
   |lists[NR_LRU_LISTS]            |
   |inactive_age                   |
   |refaults                       |
   |    (long)                     |
   |flags                          |
   |    (enum lruvec_flags)        |
   |reclaim_stat                   |
   |    (zone_reclaim_stat)        |
   |    +--------------------------+
   |    |recent_rotated[2]         | [0] for anon, [1] for file
   |    |recent_scanned[2]         |
   |    |     (unsigned long)      |
   |    |                          |
   +----+--------------------------+

