1. mem_cgroup_charge(folio, mm, gfp), called on various page fault path
================================================================================
1.1 __mem_cgroup_charge(folio, mm, gfp)
================================================================================
1.1.1 memcg = get_mem_cgroup_from_mm(mm)
================================================================================
1.1.1.1 memcg = mem_cgroup_from_task(mm->owner)
================================================================================
1.1.2 charge_memcg(folio, memcg, grp)
================================================================================
1.1.3 css_put(memcg->css)
================================================================================

2 charge_memcg(folio, memcg, grp)
================================================================================
2.1 try_charge(memcg, gfp, nr_pages)
================================================================================
2.2 css_get(memcg->css) 
================================================================================
2.3 commit_charge(folio, memcg) -> folio->memcg_data = memcg
================================================================================
2.4 mem_cgroup_charge_statistics(memcg, nr_pages)
================================================================================
2.4.1 __this_cpu_add(memcg->vmstats_percpu->nr_page_events, nr_pages);
================================================================================
2.5 memcg_check_events(memcg, folio_nid(folio))
================================================================================
2.5.1 mem_cgroup_event_ratelimit()
================================================================================
2.5.2 mem_cgroup_threshold(memcg) -> __mem_cgroup_threshold(memcg, false), notify userspace and update t->current_threshold
================================================================================
2.5.2.1 t = memcg->thresholds.primary
================================================================================
2.5.2.2 usage = mem_cgroup_usage(memcg, false)
================================================================================
2.5.3 mem_cgroup_update_tree(memcg, nid), update softlimit tree
================================================================================

3. try_charge() -> try_charge_memcg(memcg, gfp_mask, nr_pages), core for memcg accounting
================================================================================
3.1 consume_stock(memcg, nr_pages)
================================================================================
3.1.1 stock = this_cpu_ptr(&memcg_stock)
================================================================================
3.2 do_memsw_account()
================================================================================
3.3 page_counter_try_charge(&memcg->memsw, batch, counter)
================================================================================
3.4 page_counter_try_charge(&memcg->memory, batch, counter)
================================================================================
3.4.1 new = atomic_long_add_return(nr_pages, &c->usage)
================================================================================
3.4.2 propagate_protected_usage(c, new)
================================================================================
3.5 mem_over_limit = mem_cgroup_from_counter(counter, memory)
================================================================================
3.6 nr_reclaimed = try_to_free_mem_cgroup_pages(mem_over_limit, nr_pages, )
================================================================================
3.6.1 do_try_to_free_pages(zonelist, &sc)
================================================================================
3.7 drain_all_stock(mem_over_limit)
================================================================================
3.7.1 drain_local_stock(&stock->work)
================================================================================
3.7.1.1 drain_obj_stock()
================================================================================
3.7.1.2 drain_stock()
================================================================================
3.8 oom_status = mem_cgroup_oom(mem_over_limit, )
================================================================================
3.8.1 mem_cgroup_mark_under_oom(memcg)
================================================================================
3.8.2 locked = mem_cgroup_oom_trylock(memcg)
================================================================================
3.8.3 mem_cgroup_oom_notify(memcg)
================================================================================
3.8.4 mem_cgroup_unmark_under_oom(memcg)
================================================================================
3.8.5 mem_cgroup_out_of_memory(memcg, mask, order)
================================================================================
3.9 refill_stock(memcg, batch - nr_pages)
================================================================================
3.10 current->memcg_nr_pages_over_high += batch;
================================================================================
3.11 set_notify_resume(current); -> call mem_cgroup_handle_over_high() to reclaim
================================================================================

0. data struct
================================================================================

0.1 folio
================================================================================
7b230db3b8d373219f88a3d25c8fbbf12cc7f233
mm: Introduce struct folio


/* Which page is the flag stored in */
#define FOLIO_PF_ANY		0
#define FOLIO_PF_HEAD		0
#define FOLIO_PF_ONLY_HEAD	0
#define FOLIO_PF_NO_TAIL	0
#define FOLIO_PF_NO_COMPOUND	0
#define FOLIO_PF_SECOND		1

#define TESTPAGEFLAG(uname, lname, policy)				\
static __always_inline bool folio_test_##lname(struct folio *folio)	\
{ return test_bit(PG_##lname, folio_flags(folio, FOLIO_##policy)); }

#define SETPAGEFLAG(uname, lname, policy)				\
static __always_inline							\
void folio_set_##lname(struct folio *folio)				\
{ set_bit(PG_##lname, folio_flags(folio, FOLIO_##policy)); }
