1. pnv_pci_ioda_setup_dma_pe(), create iommu_group for each PE
================================================================================
iommu_register_group(tbl, pci_domain_nr(pe->pbus), pe->pe_number);

set_iommu_table_base(&pe->pdev->dev, tbl);

1.1 iommu_register_group(), create an iommu_group for each PE
================================================================================
void iommu_register_group(struct iommu_table *tbl,
		int pci_domain_number, unsigned long pe_num)
{
	struct iommu_group *grp;
	char *name;

	grp = iommu_group_alloc();
	if (IS_ERR(grp)) {
		pr_warn("powerpc iommu api: cannot create new group, err=%ld\n",
				PTR_ERR(grp));
		return;
	}
	tbl->it_group = grp;
	iommu_group_set_iommudata(grp, tbl, group_release);
	name = kasprintf(GFP_KERNEL, "domain%d-pe%lx",
			pci_domain_number, pe_num);
	if (!name)
		return;
	iommu_group_set_name(grp, name);
	kfree(name);
}

1.1.1 iommu_group_alloc(), register iommu_group in system
================================================================================
assign an ID, group->id

1.1.2 iommu_group_set_iommudata(), group arch data set to tbl
================================================================================
void iommu_group_set_iommudata(struct iommu_group *group, void *iommu_data,
			       void (*release)(void *iommu_data))
{
	group->iommu_data = iommu_data;
	group->iommu_data_release = release;
}

1.1.3 iommu_group_set_name(), /sys/kernel/iommu_group/#/group->name?
================================================================================
int iommu_group_set_name(struct iommu_group *group, const char *name)
{
	int ret;

	if (group->name) {
		iommu_group_remove_file(group, &iommu_group_attr_name);
		kfree(group->name);
		group->name = NULL;
		if (!name)
			return 0;
	}

	group->name = kstrdup(name, GFP_KERNEL);
	if (!group->name)
		return -ENOMEM;

	ret = iommu_group_create_file(group, &iommu_group_attr_name);
	if (ret) {
		kfree(group->name);
		group->name = NULL;
		return ret;
	}

	return 0;
}

1.1.3.1 iommu_group_create_file()
================================================================================
static int iommu_group_create_file(struct iommu_group *group,
				   struct iommu_group_attribute *attr)
{
	return sysfs_create_file(&group->kobj, &attr->attr);
}

1.2 set_iommu_table_base_and_group(), set iommu_group arch specific data
================================================================================
static inline void set_iommu_table_base_and_group(struct device *dev,
						  void *base)
{
	set_iommu_table_base(dev, base);
	iommu_add_device(dev);
}

1.2.1 set_iommu_table_base(), set iommu_group arch specific data
================================================================================
static inline void set_iommu_table_base(struct device *dev, void *base)
{
	dev->archdata.dma_data.iommu_table_base = base;
}

1.2.2 iommu_add_device, add the device into the iommu_group
================================================================================
int iommu_add_device(struct device *dev)
{
	struct iommu_table *tbl;

	/*
	 * The sysfs entries should be populated before
	 * binding IOMMU group. If sysfs entries isn't
	 * ready, we simply bail.
	 */
	if (!device_is_registered(dev))
		return -ENOENT;

	if (dev->iommu_group) {
		pr_debug("%s: Skipping device %s with iommu group %d\n",
			 __func__, dev_name(dev),
			 iommu_group_id(dev->iommu_group));
		return -EBUSY;
	}

	tbl = get_iommu_table_base(dev);
	if (!tbl || !tbl->it_group) {
		pr_debug("%s: Skipping device %s with no tbl\n",
			 __func__, dev_name(dev));
		return 0;
	}

	pr_debug("%s: Adding %s to iommu group %d\n",
		 __func__, dev_name(dev),
		 iommu_group_id(tbl->it_group));

	if (PAGE_SIZE < IOMMU_PAGE_SIZE(tbl)) {
		pr_err("%s: Invalid IOMMU page size %lx (%lx) on %s\n",
		       __func__, IOMMU_PAGE_SIZE(tbl),
		       PAGE_SIZE, dev_name(dev));
		return -EINVAL;
	}

	return iommu_group_add_device(tbl->it_group, dev);
}

2. How iommu_group take effect
================================================================================

2.1 pnv_pci_ioda_dma_set_mask()
================================================================================
static int pnv_pci_ioda_dma_set_mask(struct pnv_phb *phb,
				     struct pci_dev *pdev, u64 dma_mask)
{
	struct pci_dn *pdn = pci_get_pdn(pdev);
	struct pnv_ioda_pe *pe;
	uint64_t top;
	bool bypass = false;

	if (WARN_ON(!pdn || pdn->pe_number == IODA_INVALID_PE))
		return -ENODEV;;

	pe = &phb->ioda.pe_array[pdn->pe_number];
	if (pe->tce_bypass_enabled) {
		top = pe->tce_bypass_base + memblock_end_of_DRAM() - 1;
		bypass = (dma_mask >= top);
	}

	if (bypass) {
		dev_info(&pdev->dev, "Using 64-bit DMA iommu bypass\n");
		set_dma_ops(&pdev->dev, &dma_direct_ops);
		set_dma_offset(&pdev->dev, pe->tce_bypass_base);
	} else {
		dev_info(&pdev->dev, "Using 32-bit DMA via iommu\n");
		set_dma_ops(&pdev->dev, &dma_iommu_ops);
		set_iommu_table_base(&pdev->dev, &pe->tce32_table);
	}
	*pdev->dev.dma_mask = dma_mask;
	return 0;
}

2.2 dma_iommu_ops{}
================================================================================
struct dma_map_ops dma_iommu_ops = {
	.alloc			= dma_iommu_alloc_coherent,
	.free			= dma_iommu_free_coherent,
	.mmap			= dma_direct_mmap_coherent,
	.map_sg			= dma_iommu_map_sg,
	.unmap_sg		= dma_iommu_unmap_sg,
	.dma_supported		= dma_iommu_dma_supported,
	.map_page		= dma_iommu_map_page,
	.unmap_page		= dma_iommu_unmap_page,
	.get_required_mask	= dma_iommu_get_required_mask,
};

the alloc function is based on the iommu_table.

0. Data structures
================================================================================

     struct iommu_group
     +----------------------------+<------------------------------------+
     |id(int)                     |                                     |
     +----------------------------+                                     |
     |kobj                        |                                     |
     |                            |                                     |
     |devices_kobj                |     struct iommu_device             |
     +----------------------------+     +-----------------------+       |
     |devices(list_head)          |---->+list(list_head)        |       |
     | (list struct iommu_device) |     +-----------------------+       |
     +----------------------------+     |dev(struct device)     |       |
     |notifier                    |     |      iommu_group   -----------+
     |   (blocking_notifier_head) |     +-----------------------+ 
     |                            |     |name                   |
     |                            |     +-----------------------+
     |                            |
     +----------------------------+     struct iommu_table*(so one iommu_table map one iommu_group)
     |iommu_data                  |---->+---------------------+
     |   (void *)                 |     |                     |
     |iommu_data_release          |     |                     |
     |   (void (*)(void *))       |     |                     |
     |                            |     +---------------------+
     +----------------------------+
	Figure 2.1 iommu_group
